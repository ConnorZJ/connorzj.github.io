[{"title":"StarRocks01 介绍StarRocks","url":"/2023/07/29/sr01-intro/","content":"什么是 StarRocksStarRocks是次世代极速全场景的 MPP（Massively Parallel Processing）数据库，产品目标是让数据分析变得快速和简单。\nStarRocks架构简洁，采用了全面向量化引擎，并且使用了新设计的 CBO（Cost Based Optimizer）优化器，查询速度（尤其是关联查询）远超同类产品（直接报了 ClickHouse 的身份证号）。\n适用场景OLAP 多维分析利用 StarRocks 的 MPP 和向量化执行引擎，可以在雪花模型、星型模型、星座模型等场景下，能够灵活的配置进行多维化组合分析。\n实时数据仓库StarRocks 设计和实现了 Primary-Key 模型，能够在秒级内同步数据库的变化，以此可以构建实时数仓的基础。\n高并发查询StarRocks 通过良好的数据分布特性，灵活的索引以及物化视图等特性，可以解决面向用户侧的分析场景。\n统一分析\n通过使用一套系统解决多维分析、高并发查询、预计算、实时分析查询等场景，降低系统复杂度和多技术栈开发与维护成本。\n使用 StarRocks 统一管理数据湖和数据仓库，将高并发和实时性要求很高的业务放在 StarRocks 中分析，也可以使用 External Catalog 和外部表进行数据湖上的分析。\n\n系统架构架构图\nStarRocks整个系统只包含两种进程，分别是 FE（Frontend） 和 BE（Backend）。\nFE：\n\n前端节点，负责管理元数据，管理客户端连接，进行查询规划、查询调度等任务\n每个 FE 节点都会在内存中保存一份元数据，依次可以达到每个节点都能够提供无差别服务\nFE 中包含三种角色：\nLeader：Leader 通过 Follower 选举产生，选举方式采用类 Paxos 的 Berkeley DB Java Edition协议。Leader 节点提供元数据读写服务，只有Leader 才有元数据的写权限。\nFollower：只有元数据的读权限，通过同步 Leader 的元数据日志来异步地同步元数据。Follower 还参与 Leader 。\nObserver：主要用于扩展集群的查询并发能力，与 Follower 相同的是一样同步 Leader 的元数据日志，与 Follower 不同的是不参与选举。\n\n\n\nBE：\n\nBE 是后端节点，负责数据的存储，执行 SQL的任务\nFE 按照一定的策略将数据分配到 BE 节点，BE 会导入数据，形成三个副本存储，并生成相关索引\n执行 SQL 的时候，会先将 SQL 解析成逻辑执行单元， 然后在各个 BE 节点上执行物理执行单元，这样的好处是可以达到不同的机器实现本地读取计算数据，避免数据的拷贝和传输，从而提高查询效率\n\n数据管理StarRocks 采用分区分桶策略，一张表通过规则划分出多个分区，比如粒度可以按照日期划分，一天、一周、一个月等。一个分区内的数据可以按照一列或者多列进行分桶，将数据切分出多个 tablet。tablet 是 StarRocks 中的最小数据管理单元，每个 tablet 都以多副本的方式（默认 3 副本）存储在不同的 BE 节点上。\n"},{"title":"StarRocks02 快速开始","url":"/2023/07/31/sr02-quickstart/","content":"本地部署 StarRocks\n由于这里是学习 StarRocks，所以使用 Docker 来部署一个单机版的服务\n\n本地部署 StarRocks，一共需要启动 FE 和 BE 两个进程。\n拉取镜像执行命令docker run starrocks/allin1-ubuntu\n启动 StarRocksdocker run -d -p 9030:9030 -p 8030:8030 -p 8040:8040 -itd starrocks/allin1-ubuntu\n\n执行以上命令即可启动 StarRocks 的 FE 和 BE，其中 9030 是 StarRocks 的 MySQL 协议通信端口，8030 和 8040 分别是 FE 和 BE 的 HTTP 通信端口，如果有端口冲突的话需要自行修改。\n连接 StarRocksStarRocks 启动之后，通过MySQL 客户端连接到 StarRocks 集群：\nmysql -u root -h 127.0.0.1 -P 9030 --prompt=&quot;StarRocks &gt; &quot;\n\n\n9030 为 docker 启动时指定的 MySQL 客户端通信端口\n\n想要查看 FE 节点的状态，可以通过以下 SQL：\nshow proc &#x27;/frontends&#x27;\\G\n\n结果如下：\nStarRocks &gt;show proc &#x27;/frontends&#x27;\\G*************************** 1. row ***************************             Name: 83db74e6f98a_9010_1690421440035               IP: 83db74e6f98a      EditLogPort: 9010         HttpPort: 8030        QueryPort: 9030          RpcPort: 9020             Role: LEADER        ClusterId: 512154616             Join: true            Alive: trueReplayedJournalId: 49444    LastHeartbeat: 2023-08-01 11:14:42         IsHelper: true           ErrMsg:        StartTime: 2023-07-27 01:30:49          Version: 3.1.0-rc01-64ca37e8631 row in set (0.36 sec)\n\n\nHttpPort 为 8030，在启动 StarRocks 命令中指定的端口\nQueryPort 为 9030，为当前 MySQL 客户端连接的端口\nRole 表示当前 FE 节点的角色，因为只有一个 FE，所以默认为 Leader\nAlive 为 true，表示当前 FE 节点运行正常\n\n想要查看 BE 节点的状态，可以通过以下 SQL：\nSHOW PROC &#x27;/backends&#x27;\\G\n\n结果如下：\nStarRocks &gt;show proc &#x27;/backends&#x27;\\G*************************** 1. row ***************************            BackendId: 10004                   IP: 83db74e6f98a        HeartbeatPort: 9050               BePort: 9060             HttpPort: 8040             BrpcPort: 8060        LastStartTime: 2023-07-27 01:30:58        LastHeartbeat: 2023-08-01 11:20:18                Alive: true SystemDecommissioned: falseClusterDecommissioned: false            TabletNum: 40     DataUsedCapacity: 0.000        AvailCapacity: 46.409 GB        TotalCapacity: 58.367 GB              UsedPct: 20.49 %       MaxDiskUsedPct: 20.49 %               ErrMsg:              Version: 3.1.0-rc01-64ca37e863               Status: &#123;&quot;lastSuccessReportTabletsTime&quot;:&quot;2023-08-01 11:19:35&quot;&#125;    DataTotalCapacity: 46.409 GB          DataUsedPct: 0.00 %             CpuCores: 4    NumRunningQueries: 0           MemUsedPct: 0.17 %           CpuUsedPct: 0.7 %1 row in set (0.02 sec)\n\n\nHttpPort 为 8040，在启动 StarRocks 命令中指定的端口\nAlive 为 true，表示当前 BE 节点启动正常\n\n停止 StarRocks 服务使用docker ps命令获取当前 StarRocks 容器ID，然后执行docker stop container_id即可停止 StarRocks 服务\n创建表及相关操作创建数据库和表首先通过 MySQL 客户端连接到 StarRocks 集群，在编写 SQL 的时候，几乎完全可以使用 MySQL 的语法来创建数据库或表。\ncreate database example_db;\n\n创建好了数据库后，接着开始创建表：\ncreate table if not exists example_db.detailDemo(    recruit_date date         not null comment &#x27;YYYY-MM-DD&#x27;,    region_num   tinyint comment &#x27;range [-128, 127]&#x27;,    num_plate    smallint comment &#x27;range [-32768, 32767]&#x27;,    tel          int comment &#x27;range [-2147483648, 2147483647]&#x27;,    id           bigint comment &#x27;range[-2^63+1 ~ 2^63-1]&#x27;,    password     largeint comment &#x27;range [-2^127+1 ~ 2^127-1]&#x27;,    name         char(20)     not null comment &#x27;range char(m), m in (1-255)&#x27;,    profile      varchar(500) not null comment &#x27;upper limit values 1048576 bytes&#x27;,    hobby        string       not null comment &#x27;upper limit values 65533 bytes&#x27;,    leave_time   datetime comment &#x27;YYYY-MM-DD HH:MM:SS&#x27;,    channel      float comment &#x27;4 bytes&#x27;,    income       double comment &#x27;8 bytes&#x27;,    account      decimal(12, 4) comment &#x27;&#x27;,    ispass       boolean comment &#x27;true/false&#x27;) engine = olapduplicate key (recruit_date, region_num)partition by range(recruit_date)(  partition p20220311 values [(&#x27;2022-03-11&#x27;), (&#x27;2022-03-12&#x27;)),  partition p20220312 values [(&#x27;2022-03-12&#x27;), (&#x27;2022-03-13&#x27;)),  partition p20220313 values [(&#x27;2022-03-13&#x27;), (&#x27;2022-03-14&#x27;)),  partition p20220314 values [(&#x27;2022-03-14&#x27;), (&#x27;2022-03-15&#x27;)),  partition p20220315 values [(&#x27;2022-03-15&#x27;), (&#x27;2022-03-16&#x27;)))distributed by hash(recruit_date, region_num);\n\n\n注意：StarRocks 中，字段不区分大小写，但是表名区分大小写\n\n以上创表语句中，partition by表示给表创建分区，上述例子是以recruit_date进行范围分区从 2022-03-11 日到 2022-03-15 日总共分成了 5 个分区（注意每日分区中是左闭右开），distributed by是用来创建分桶的语法，以上使用 recruit_date, region_num两列当做分桶列，分桶数量支持 StarRocks 自动设置，无需用户手动设置。\nduplicate关键字表示当前这张表为明细模型，key 中的列表示这张表的排序列。\nStarRocks 支持多种数据模型，分别是明细模型，聚合模型，更新模型和主键模型，每个模型都有各种的优点，适合使用在不同的场景，以提高分析效率。\nengine 类型默认就为 olap，对应 StarRocks 中的内部表，其他 engine 还可以选用 mysql、elasticsearch、hive、jdbc、hudi、iceberg。\n修改表结构在 StarRocks 中，可以通过 alert table的方式来给表进行 DDL 操作（目前还不支持修改字段名称）\n增加列ALTER TABLE detailDemo ADD COLUMN uv BIGINT DEFAULT &#x27;0&#x27; after ispass;\n\n增加一个名称为 uv，类型为 bigint， 默认值为 0 的列，加载 ispass 列的后面\n删除列ALTER TABLE detailDemo DROP COLUMN uv;\n\n查看 DDL 语句执行状态SHOW ALTER TABLE COLUMN\\G;\n\n由于修改列等操作的是异步执行的，所以可以通过这条语句查看正在执行的 DDL 语句执行状态：\nStarRocks &gt;SHOW ALTER TABLE COLUMN\\G;*************************** 1. row ***************************        JobId: 10127    TableName: detailDemo   CreateTime: 2023-08-01 12:01:21   FinishTime: 2023-08-01 12:01:46    IndexName: detailDemo      IndexId: 10128OriginIndexId: 10106SchemaVersion: 1:981209089TransactionId: 2        State: FINISHED          Msg:     Progress: NULL      Timeout: 86400*************************** 2. row ***************************        JobId: 10149    TableName: detailDemo   CreateTime: 2023-08-01 12:01:58   FinishTime: 2023-08-01 12:02:26    IndexName: detailDemo      IndexId: 10150OriginIndexId: 10128SchemaVersion: 2:283111440TransactionId: 3        State: FINISHED          Msg:     Progress: NULL      Timeout: 864002 rows in set (0.00 sec)\n\n由于执行了上述例子中的添加和删除列的操作，目前查询出来的结果就会有两条，可以看到 State 为 FINISHED， 表示目前已经全部执行完成了。\n当然也可以取消正在执行的 DDL 作业：\nCANCEL ALTER TABLE COLUMN FROM table_name\\G;\n\n\n\n导入数据到 StarRocksStarRocks 导入数据的方式主要分为以下五种：\nBroker LoadBroker Load 是一种异步导入的方式，通过 Broker 进程访问读取外部数据源，采用 MySQL 协议的方式导入到 StarRocks\nBroker Load 模式可以支撑百 GB 的数据量导入，支持该方式的数据源有 Hive等\nSpark LoadSpark Load 是一种异步导入的方式，通过 Spark 引擎对导入数据进行预处理，提高 StarRocks 导入数据的性能，并且节省 StarRocks 集群的计算资源\nStream LoadStream Load 是一种同步导入的方式，通过 HTTP 的方式把数据上报给 StarRocks，然后同步等待导入结果，从而判断导入是否成功。\nStream Load 适用于本地文件导入，或者是数据流的方式导入，支持该方式的有 Flink、CSV 等\nRoutine LoadRoutine Load 通过提交一个例行导入作业，生成一个常驻线程，不间断的从数据源中读取数据并导入到 StarRocks，适用于 Kafka\nInsert IntoInsert Into 导入模式是一种同步数据导入模式，类似 MySQL 中的 Insert 语句，StarRocks 支持通过 INSERT INTO tbl SELECT ...; 的方式从 StarRocks 的表中读取数据并导入到另一张表。您也可以通过 INSERT INTO tbl VALUES(...); 插入单条数据。该导入方式支持的数据源有 DataX&#x2F;DTS、Kettle&#x2F;Informatic、以及 StarRocks 本身。\n通过 StreamLoad 导入数据2022-03-13,1,1212,1231231231,123412341234,123452342342343324,hello,welcome,starrocks,2022-03-15 12:21:32,123.04,21.12345,123456.123456,true2022-03-14,2,1212,1231231231,123412341234,123452342342343324,hello,welcome,starrocks,2022-03-15 12:21:32,123.04,21.12345,123456.123456,false\n\n以上文本为example_db.detailDemo表的数据文件，格式为 csv，保存此文件到本地后，使用 HTTP 的方式向 StarRocks 进行导入：\ncurl --location-trusted -u root: -T detailDemo_data -H &quot;label: streamDemo&quot; \\-H &quot;column_separator:,&quot; \\http://127.0.0.1:8030/api/example_db/detailDemo/_stream_load\n\n\n\n"}]